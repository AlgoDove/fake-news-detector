{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f901f6-985d-422f-b518-07ddd0bec7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "\n",
    "# Suppress minor warnings for a cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def train_and_evaluate(X_train_tfidf, X_test_tfidf, y_train, y_test, vectorizer):\n",
    "    \"\"\"\n",
    "    Runs Grid Search CV to tune Logistic Regression, evaluates the best model,\n",
    "    and saves the champion model and vectorizer to the 'models/' directory.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Model 4: Hyperparameter Tuning with GridSearchCV ---\")\n",
    "    \n",
    "    # Define the hyperparameter grid (exactly as in your notebook)\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10],          \n",
    "        'solver': ['liblinear', 'saga']  \n",
    "    }\n",
    "\n",
    "    # Setup for GridSearchCV\n",
    "    logreg_tuned = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    kfold_cv_inner = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=logreg_tuned,\n",
    "        param_grid=param_grid,\n",
    "        cv=kfold_cv_inner,\n",
    "        scoring='f1', \n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    print(\"Starting GridSearchCV with 5-Fold Cross-Validation...\")\n",
    "    grid_search.fit(X_train_tfidf, y_train)\n",
    "\n",
    "    # Retrieve the best estimator\n",
    "    best_logreg = grid_search.best_estimator_\n",
    "    print(f\"\\nBest Hyperparameters found: {grid_search.best_params_}\")\n",
    "\n",
    "    # Evaluate the best tuned model on the unseen test set\n",
    "    y_pred_best = best_logreg.predict(X_test_tfidf)\n",
    "    final_accuracy = accuracy_score(y_test, y_pred_best)\n",
    "    \n",
    "    print(f\"\\nAccuracy (Best Tuned Model) on Test Set: {final_accuracy:.4f}\")\n",
    "    print(\"Classification Report (Best Tuned Model):\\n\", classification_report(y_test, y_pred_best))\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred_best)\n",
    "    print(\"\\nConfusion Matrix for the Optimal Tuned Model\")\n",
    "    print(cm)\n",
    "\n",
    "    # --- Saving the Champion Model and Vectorizer (CRITICAL STEP) ---\n",
    "    # NOTE: Paths are relative to the project root for consistency.\n",
    "    joblib.dump(best_logreg, 'models/champion_lr_model.pkl')\n",
    "    joblib.dump(vectorizer, 'models/fitted_vectorizer.pkl')\n",
    "    print(\"\\nSUCCESS: Champion model and fitted vectorizer saved to the 'models/' folder.\")\n",
    "    \n",
    "    return final_accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
